// @generated by protoc-gen-es v1.9.0
// @generated from file msp/azure/openai/v1/embeddings.proto (package msp.azure.openai.v1, syntax proto3)
/* eslint-disable */
// @ts-nocheck

import { proto3 } from "@bufbuild/protobuf";

/**
 * @generated from message msp.azure.openai.v1.EmbeddingRequest
 */
export const EmbeddingRequest = /*@__PURE__*/ proto3.makeMessageType(
  "msp.azure.openai.v1.EmbeddingRequest",
  () => [
    { no: 1, name: "input", kind: "scalar", T: 9 /* ScalarType.STRING */ },
    { no: 2, name: "user", kind: "scalar", T: 9 /* ScalarType.STRING */ },
    { no: 3, name: "input_type", kind: "scalar", T: 9 /* ScalarType.STRING */ },
  ],
);

/**
 * @generated from message msp.azure.openai.v1.EmbeddingResponse
 */
export const EmbeddingResponse = /*@__PURE__*/ proto3.makeMessageType(
  "msp.azure.openai.v1.EmbeddingResponse",
  () => [
    { no: 1, name: "object", kind: "scalar", T: 9 /* ScalarType.STRING */ },
    { no: 2, name: "model", kind: "scalar", T: 9 /* ScalarType.STRING */ },
    { no: 3, name: "data", kind: "message", T: Data, repeated: true },
    { no: 4, name: "usage", kind: "message", T: EmbeddingResponse_Usage },
  ],
);

/**
 * @generated from message msp.azure.openai.v1.EmbeddingResponse.Usage
 */
export const EmbeddingResponse_Usage = /*@__PURE__*/ proto3.makeMessageType(
  "msp.azure.openai.v1.EmbeddingResponse.Usage",
  () => [
    { no: 1, name: "prompt_tokens", kind: "scalar", T: 13 /* ScalarType.UINT32 */ },
    { no: 2, name: "total_tokens", kind: "scalar", T: 13 /* ScalarType.UINT32 */ },
  ],
  {localName: "EmbeddingResponse_Usage"},
);

/**
 * @generated from message msp.azure.openai.v1.Data
 */
export const Data = /*@__PURE__*/ proto3.makeMessageType(
  "msp.azure.openai.v1.Data",
  () => [
    { no: 1, name: "index", kind: "scalar", T: 13 /* ScalarType.UINT32 */ },
    { no: 2, name: "object", kind: "scalar", T: 9 /* ScalarType.STRING */ },
    { no: 3, name: "embedding", kind: "scalar", T: 2 /* ScalarType.FLOAT */, repeated: true },
  ],
);

